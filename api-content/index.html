{"posts":[{"title":"IO多路复用","content":"为什么需要I/O多路复用 IO多路复用的本质是为了提升操作系统维护对外连接的能力，在尽可能节省资源的同时，在网络编程中提升操作系统维护Socket的能力。 在基础的TCP Socket通信模型下，服务端和客户端会分别通过Socket建立一对一的连接，大致流程如下： 服务端创建Socket（可选网络层和传输层协议），并使用bind()绑定IP和端口，启动调用listen()开始监听连接 客户端创建Socket（可选网络层和传输层协议），使用connect()建立连接 接下来进行TCP三次握手，完成后，服务端使用accept()从TCP全连接队列中取出该socket，进行数据传输 这个过程中，服务端的进程会通过自己的文件描述符数组找到自己在内核中的Socket数据结构，其中包含一个发送队列和一个接收队列，两个队列里存放了许多sk_buff，它们由链表的形式进行组织。 多进程模型：如果我们需要让服务器连接多个客户端，最简单的方案便是创建多个进程，父进程使用fork()创建和自己一样的子进程。在创建时，两个进程除了返回值是一模一样的，这就包括了指向Socket的文件描述符，即子进程可以使用父进程的“已连接Socket”进行通信。 但这一模型下存在一个巨大的问题，便是资源消耗。进程有自己独立的地址空间，包括虚拟内存、进程栈、内核堆栈等等资源，多进程的上下文切换代价极大。此外，子进程退出时，如有未被及时回收的子进程资源便会产生大量僵尸进程，消耗系统资源，这时我们便会考虑代价更小的多线程模型。 多线程模型：总所周知，同一进程内的线程会共享线程栈以外的一切资源，包括文件描述符列表、代码、全局数据等等，其资源消耗和上下文切换代价比进程要小得多。当然，在网络连接的场景下，频繁创建和销毁大量线程的代价也决不可小觑，这时我们便可以考虑使用线程池。 父进程可以通过创建一个队列（注意线程安全），将accept()取得的已连接Socket连接放入该队列中，线程池则从其中取出已连接Socket进行处理。但当服务器需要维护的连接达到更大规模时（参考C10K），大量线程带来的消耗也是相当恐怖的。 这时我们便会想能否使用一种方式无需创建大量进程或线程，以更小的代价让操作系统维护更多的连接？ I/O多路复用 I/O多路复用（Input/Output Multiplexing）是一种在单个线程中管理多个输入/输出通道的技术。它允许一个线程同时监听多个输入流（比如文件描述符），并在有数据可读或可写时进行相应的处理，而不需要为每个通道创建一个独立的线程。 常见的I/O多路复用机制包括select、poll和epoll. select 数据结构：bitsmap[FD_SETSIZE] fd检查：轮询 应用场景：低并发需求，有少量的fd需要监控 select会将已连接的Socket文件描述符集合拷贝到内核空间，内核遍历整个Socket集合检查连接中是否有网络事件发生，并标记该Socket为可读或可写，然后将这个集合整个拷贝回用户空间，在用户空间中再次遍历找到那些被标记的Socket，并进行处理。 整个过程发生了2次拷贝和两次遍历，随着文件描述符的增加，其性能会线性下降（线性数据结构遍历O(n)O(n)O(n)、反复拷贝操作）； select表示文件描述符集合的数据结构是固定长度的BitsMap，大小由内核FD_SETSIZE宏定义，默认值为1024，即select最多可以监听0~1023的文件描述符。 poll 数据结构：结构体数组 fd检查：轮询 应用场景：低并发需求，有大量的fd需要监控 poll在select的基础上将底层数据结构改为结构体数组，解决了select文件描述符上限的问题。由此，在连接数较多时，性能会优于select。 epoll 数据结构：红黑树 fd检查：事件驱动 应用场景：高并发需求，有大量fd需要监控，fd活跃数较低 epoll在内核中维护了一个红黑树。调用epoll_ctl()将需要监控的socket放入内核的数据结构中，解决了select/poll每次都完整拷贝整个数据结构和时间复杂度高的问题（红黑树增删改效率一般为O(logn)O(logn)O(logn)）。 epoll引入了事件驱动机制和回调机制。epoll在内核中维护了一个就绪队列，仅在fd状态有改变时才会触发回调，当用户调用 epoll_wait() 函数时，只会返回有事件发生的文件描述符的个数。解决了select/poll完整轮询遍历整个socket列表的问题，且在fd活跃数较低时，epoll优势更加明显。 epoll的事件触发 epoll支持两种事件触发模式：水平触发（level-triggered，LT）和边缘触发（edge-triggered，ET）。 水平触发（LT） 边缘触发（ET） 触发条件 只要文件描述符（fd）对应的事件条件满足（如缓冲区有数据可读或可写），每次调用epoll_wait都会触发。 只有在fd状态发生变化的边缘时刻触发，如从不可读变为可读、从不可写变为可写时触发，之后状态不变则不再触发（除非再次变化）。 事件通知频率 相对较高。如果应用程序处理事件不及时，会频繁收到相同事件的通知。 相对较低。只有状态改变边缘才触发，减少了不必要的通知。 编程难度 较简单。开发人员可以按照自己的节奏处理事件，不用担心错过事件，因为会持续收到通知。 较复杂。要求应用程序在一次触发后尽可能完整地处理相关事件，否则可能错过事件，需要更精细的编程逻辑。 适用场景 适用于简单的网络编程场景或对性能要求不是极高，处理事件速度能跟上的情况。 适用于高并发、高性能要求的场景，如大型网络服务器，能有效降低系统开销。 数据处理方式 可以每次处理部分数据，剩余数据下次调用epoll_wait时还会收到通知。 通常需要在一次触发后循环处理数据，尽量一次性处理完所有相关数据，否则可能遗漏。 参考阅读 9.2 I/O 多路复用：select/poll/epoll | 小林coding 什么是IO 多路复用（超详细-读这一篇就够）_io多路复用是什么-CSDN博客 ","link":"https://timestarry.github.io/post/os-io-multiuse/"},{"title":"线程同步：锁、条件变量、信号量","content":"不同于进程拥有独立的地址，同一进程内的线程除了线程栈外其他数据都是共享的，所以我们要着重关注线程安全问题。线程安全技术包括原子操作和线程同步。原子操作通过确保不可分割的汇编指令实现了线程执行的安全性，这种方法高效，但只适用于较为简单的场景，例如修改某个变量、实现计数等场景。本文着重关注线程同步的方法。 在多线程编程中，线程同步是保证多个线程能够正确、安全地访问共享资源的关键技术。由于线程的调度是不确定的，不加控制的并发访问可能会导致数据竞争（race condition），最终引发不可预测的错误或崩溃。 由此，线程同步的核心目标是确保多个线程对共享资源的访问是有序的、互斥的，防止多个线程同时对同一个资源进行读写操作而导致数据不一致或资源破坏。 针对不同的场景，我们常用这些手段来实现线程同步：锁、信号量、条件变量。 锁 锁（Lock）是最常见的线程同步机制，用于保证同一时刻只有一个线程能访问共享资源。锁通过保护临界区（critical section）来防止多个线程同时修改共享数据，从而避免数据竞争。 常见的锁类型包括：互斥锁（mutex）、读写锁（read-write lock）、自旋锁（spinlock）。互斥锁是最基本的线程同步原语，读写锁和自旋锁分别针对大量读场景和短时间持有锁两种情况做了特定优化，在实际编程中应根据具体场景选择锁类型。 互斥锁 互斥锁是最基本的锁机制，一个线程获得锁后，其他线程必须等待，直到锁被释放。互斥锁保证了同一时间只有一个线程能够访问共享资源。 实现用例 #include &lt;iostream&gt; #include &lt;thread&gt; #include &lt;mutex&gt; std::mutex mtx; // 定义互斥锁 int count = 0; void increment() { for (int i = 0; i &lt; 100000; ++i) { // 通过加锁保证了count在同一时刻仅会被一个线程操作，但每次count计数都会加锁解锁，将导致严重的性能问题 mtx.lock(); ++count; mtx.unlock(); } } int main() { std::thread t1(increment); std::thread t2(increment); t1.join(); t2.join(); std::cout &lt;&lt; &quot;Final count: &quot; &lt;&lt; count &lt;&lt; std::endl; } 优点 简单：实现简单，易于理解； 保护临界资源：有效地保护临界区，确保同一时间只有一个线程可以访问共享资源。 缺点 可能导致死锁：如果线程在持有A锁的情况下等待B锁，而B锁又被另一个线程持有，并且也在等待A锁，这将会产生死锁； 性能消耗：频繁地锁定和解锁操作会造成性能开销； 优先级反转：高优先级进程可能会因为等待低优进程释放锁而阻塞，导致性能下降。 读写锁 读写锁有三种状态：读锁、写锁、不加锁。 某线程申请了读锁：其他线程可以再申请读锁，但不能申请写锁； 某线程申请了写锁：其他线程不允许申请读锁或写锁，即独占锁。 优点 提高并发性：允许多个读操作同时进行，只在写操作时才完全互斥，适用于读多写少的场景； 分离读写控制：读写锁能够更好地控制对共享资源的访问，读操作不会阻塞其他读操作。 缺点 复杂度：相对于互斥锁，读写锁的实现和使用较为复杂； 写操作饥饿：如果持续有读操作，写操作可能会长时间等待，导致写操作“饥饿”。 自旋锁 自旋锁与互斥锁类似，但是它不会使线程进入阻塞状态，而是持续循环检测锁的状态（轮询），直到获取锁。 优点 无阻塞：线程在尝试获取锁时不会进行上下文切换，适用于锁只会被持有很短时间的场景； 避免线程切换：由于线程不会进入睡眠状态，因此可以减少线程切换的开销。 缺点 CPU消耗：如果锁被持有时间较长，自旋锁会导致CPU空转，浪费处理器资源； 不公平：某些自旋锁的实现可能导致线程饥饿或优先级反转问题。 条件变量 条件变量允许线程等待某个条件满足后再继续执行，常用于生产者-消费者问题。它结合互斥锁一起使用，等待线程在条件满足时被唤醒，解决了互斥锁仅有锁定或非锁定两种状态的问题。 实现用例：在C++中引入条件变量 包含头文件 &lt;condition_variable&gt; 和 &lt;mutex&gt;； 创建一个互斥锁 std::mutex 和一个条件变量 std::condition_variable； 在需要等待条件的线程中，首先锁定互斥锁，然后检查条件是否满足。如果不满足条件，则调用条件变量的 wait 方法，同时会自动解锁互斥锁，使其他线程可以访问共享资源。当其他线程通知条件变量时，等待的线程会被唤醒，并重新锁定互斥锁； 在通知条件的线程中，锁定互斥锁，修改共享资源使得条件满足，然后调用条件变量的 notify_one 或 notify_all 方法来通知等待的线程。 /* 生产者线程不断生产数据并放入队列中，当队列满时，生产者线程等待。消费者线程不断从队列中取出数据，当队列为空时，消费者线程等待。通过条件变量和互斥锁的配合，实现了生产者和消费者的同步。 */ #include &lt;iostream&gt; #include &lt;thread&gt; #include &lt;mutex&gt; #include &lt;condition_variable&gt; #include &lt;queue&gt; // 互斥锁，用于保护共享资源 data_queue std::mutex mutex_; // 条件变量，用于线程间的等待和通知 std::condition_variable condition_; // 存储数据的队列，作为生产者和消费者共享的资源 std::queue&lt;int&gt; data_queue; // 队列的最大容量 const int max_queue_size = 5; // 生产者函数 void producer() { for (int i = 0; i &lt; 10; ++i) { // 创建 unique_lock，在构造时自动锁定互斥锁 std::unique_lock&lt;std::mutex&gt; lock(mutex_); // 当队列已满时，等待条件变量的通知 while (data_queue.size() == max_queue_size) { condition_.wait(lock); } // 将数据放入队列 data_queue.push(i); std::cout &lt;&lt; &quot;Produced: &quot; &lt;&lt; i &lt;&lt; std::endl; // 通知消费者线程，可能有数据可供消费了 condition_.notify_one(); } } // 消费者函数 void consumer() { while (true) { // 创建 unique_lock，在构造时自动锁定互斥锁 std::unique_lock&lt;std::mutex&gt; lock(mutex_); // 当队列为空时，等待条件变量的通知 while (data_queue.empty()) { condition_.wait(lock); } // 取出队列中的数据 int data = data_queue.front(); data_queue.pop(); std::cout &lt;&lt; &quot;Consumed: &quot; &lt;&lt; data &lt;&lt; std::endl; // 通知生产者线程，可能有空间可以生产新数据了 condition_.notify_one(); } } int main() { // 创建生产者线程并执行 producer 函数 std::thread producer_thread(producer); // 创建消费者线程并执行 consumer 函数 std::thread consumer_thread(consumer); // 等待生产者线程结束 producer_thread.join(); // 等待消费者线程结束 consumer_thread.join(); return 0; } 信号量 信号量（Semaphore）用于控制访问资源的线程数量，常用于限制某一资源的并发访问次数。C++ 标准库中没有直接提供信号量，应通过第三方库或者使用自定义实现。 分类 二元信号量（Binary Semaphore）：与互斥锁类似，值只允许为 0 或 1，用于确保只有一个线程访问资源； 计数信号量（Counting Semaphore）：可以允许多个线程同时访问，信号量的值表示可供访问的资源数量。 与锁的关系 锁主要是为了互斥，保证只有一个线程能访问资源；信号量则可以限制多个线程并发访问，适合资源有限的场景； 信号量在控制资源数量时更加灵活，而锁一般用于单一资源的保护。 自定义信号量实现 实现一个基本的信号量基类应包含这些能力：计数、获取、释放。 #include &lt;iostream&gt; #include &lt;thread&gt; #include &lt;mutex&gt; #include &lt;condition_variable&gt; #include &lt;vector&gt; // 信号量类 class Semaphore { private: std::mutex mutex_; // 互斥锁，用于同步对计数的访问 std::condition_variable condition_; // 条件变量，用于线程等待和通知 size_t count_; // 计数，表示可用资源的数量 public: // 构造函数，初始化信号量计数 Semaphore(size_t count = 1) : count_(count) {} // 获取信号量，减少计数，如果计数小于等于0，则线程等待 void acquire() { std::unique_lock&lt;std::mutex&gt; lock(mutex_); // 使用条件变量的wait函数等待，直到计数大于0 condition_.wait(lock, [this] { return count_ &gt; 0; }); // 减少计数，表示获取了一个资源 --count_; } // 释放信号量，增加计数，并通知一个等待的线程 void release() { std::lock_guard&lt;std::mutex&gt; lock(mutex_); // 增加计数，表示释放了一个资源 ++count_; // 通知一个等待的线程（如果有） condition_.notify_one(); } }; int shared_resource = 0; // 共享资源 Semaphore semaphore(3); // 信号量，允许最多3个线程同时访问资源 // 工作线程函数 void worker() { semaphore.acquire(); // 获取信号量，进入临界区 // 执行一些操作，比如增加共享资源 std::cout &lt;&lt; &quot;Thread &quot; &lt;&lt; std::this_thread::get_id() &lt;&lt; &quot; is accessing the shared resource.&quot; &lt;&lt; std::endl; ++shared_resource; // 增加共享资源的值 std::this_thread::sleep_for(std::chrono::seconds(1)); // 模拟耗时操作 semaphore.release(); // 释放信号量，离开临界区 } int main() { std::vector&lt;std::thread&gt; threads; // 存储线程的向量 // 创建并启动多个线程 for (int i = 0; i &lt; 10; ++i) { threads.emplace_back(worker); } // 等待所有线程完成 for (auto&amp; thread : threads) { thread.join(); } // 打印共享资源的最终值 std::cout &lt;&lt; &quot;Final value of shared resource: &quot; &lt;&lt; shared_resource &lt;&lt; std::endl; return 0; } 参考阅读 线程同步的几种方式 - 知乎 (zhihu.com) 基本功 | 一文讲清多线程和多线程同步 - 美团技术团队 (meituan.com) 多线程编程：一次性搞懂线程同步机制_哔哩哔哩_bilibili 线程池的信号量-阿里云开发者社区 (aliyun.com) ","link":"https://timestarry.github.io/post/os-thread-sync/"},{"title":"栈与队列","content":"栈 栈（Stack）是先进后出的数据结构，我们可以将其想象为一个杯子，入栈就是不断往杯子中放入大小合适的小球，出栈时需要将小球从上至下一个个取出。 由此带来的访问入栈（push）、栈顶元素（top）、弹出栈顶（pop）时间复杂度都是O(1)O(1)O(1). 栈的常见应用场景 程序内存管理：函数栈，用于记录函数的上下文信息； 撤销与重做：撤销操作时将操作入栈，重做时将撤销的操作一个个出栈。 栈的两种实现方式 我们可以使用数组或链表来实现栈，两种实现方式可以完成的栈功能都是一致的，但由于两种基本数据结构特性的不同，在部分操作的性能上存在差异。 使用数组实现时，为避免手动处理扩容问题，应使用动态数组实现。 两种实现方式的简单对比： 数组实现（数组尾部作栈顶） 链表实现（链表头节点作栈顶） 入栈（push） 添加尾部元素（push_back） 添加头节点（new-&gt;next = head;head = new-&gt;next） 访问栈顶（top） 访问尾部元素（back） 访问头节点（head-&gt;val） 出栈（pop） 删除尾部元素（pop_back） 删除头节点（head = head-&gt;next;delete） 时间效率 出入栈操作涉及到的内存均已预先分配，操作效率较高；但入栈时若超出数组容量会触发数组扩容，导致该次入栈操作时间复杂度变为O(n)O(n)O(n)，不过由于扩容是低频操作，平均效率较高。 链表不存在数组扩容的问题，但元素入栈需要初始化节点对象并修改指针，效率较低，若入栈元素本身就是节点对象则可省去初始化操作，提高效率。平均效率表现更稳定。 空间效率 初始化数组的空间可能是超出需求的，扩容机制按2倍或其它倍率扩容时也可能导致过多的空间浪费。 链表节点需要额外存储指针。两者具体空间效率要具体情况具体分析。 STL stack C++STL stack容器提供如下操作： STL 函数 描述 操作时间复杂度 empty() 判断栈是否为空 O(1)O(1)O(1) size() 返回栈中元素的个数 O(1)O(1)O(1) top() 返回栈顶元素 O(1)O(1)O(1) push(element) 将元素压入栈顶 O(1)O(1)O(1) pop() 弹出栈顶元素 O(1)O(1)O(1) 队列 队列（Queue）是先进先出的数据结构，如同排队一样，我更喜欢将其想象为两端开口的管道，入队便是向管道入口放入小球，出队便是从管道出口取出小球，管道两端分别是只允许入或出的队尾和队首。 由此带来的入队（push）、访问队首（front）、出队（pop）时间复杂度均为O(1)O(1)O(1). 队列的常见应用场景 进程调度：例如，就绪队列中存储着处于就绪状态等待被调度执行的进程，当 CPU 空闲时，操作系统从就绪队列中选择一个进程进行执行； 消息队列：在分布式 Web 服务架构中，不同的服务组件之间可以通过消息队列进行通信。例如，订单服务在处理完一个订单后，可以将订单处理完成的消息放入消息队列。 队列的两种实现方式 使用链表实现队列的思路比较常规，初始化头（front）尾（rear）节点，指向队列的头尾，并且规定队尾仅可添加，队首仅可删除，记录出入队记录队列长度（size）即可。 但Hello-algo中使用数组实现就比较妙了，它采用的方式是环形数组，所以这里着重讲一下环形数组实现队列的方法。示例实现这一方法时采用了queCapacity描述队列容量，即数组上限，当然也可采用动态数组的形式进行扩容。 环形数组实现队列 使用数组实现队列时需要考虑解决这两个问题： 在数组中删除首元素的时间复杂度为O(n)O(n)O(n)（删除并移动元素），可以使用队首指针front和长度size对队列有效范围进行规定，然后定义队尾rear = front + size，如此数组中队列的有效区间便为[front,rear−1][front, rear - 1][front,rear−1]； 在不断的出入队过程中，front和rear移动到数组的尾部时将无法继续移动，解决方案是将数组视为首尾相接的环形数组。具体操作是让front或rear越过数组尾部时回到数组头部继续遍历，方法是取余。 // 基于环形数组实现的队列 class ArrayQueue { private: int* nums; // 用于存储队列元素的数组 int front; // 队首指针，指向队首元素 int queSize; // 队列长度 int queCapacity; // 队列容量 public: ArrayQueue(int capacity) { // 初始化队列 nums = new int[capacity]; front = 0; queSize = 0; queCapacity = capacity; } ~ArrayQueue() { delete[] nums; } // 队列容量 int capacity() { return queCapacity; } // 队列大小 int size() { return queSize; } // 队列是否为空 bool empty() { if (queSize == 0) return true; else return false; } // 访问队首 int front() { if (empty()) { std::cout &lt;&lt; &quot;队列为空&quot; &lt;&lt; std::endl; return; } return nums[front]; } // 访问队尾 int back() { if (empty()) { std::cout &lt;&lt; &quot;队列为空&quot; &lt;&lt; std::endl; return; } return nums[front + queSize - 1]; } // 入队 void push(int num) { if (queSize == queCapacity) { std::cout &lt;&lt; &quot;队列已满&quot; &lt;&lt; std::endl; return; } int rear = (front + queSize) % queCapacity; // 取余：rear越过数组尾部回到头部 nums[rear] = num; queSize++; } // 出队 int pop() { if (empty()) { std::cout &lt;&lt; &quot;队列为空&quot; &lt;&lt; std::endl; return; } front = (front + 1) % queCapacity; // 取余：front越过数组尾部回到头部 queSize--; } }; STL queue C++ STL queue容器提供如下操作： STL 函数 描述 操作时间复杂度 empty() 判断队列是否为空 O(1)O(1)O(1) size() 返回队列中元素的个数 O(1)O(1)O(1) front() 返回队首元素 O(1)O(1)O(1) back() 返回队尾元素 O(1)O(1)O(1) push(element) 将元素压入队尾 O(1)O(1)O(1) pop() 弹出队首元素。 O(1)O(1)O(1) 双向队列 不同于队列仅允许单进单出，双向队列（double-ended queue）允许在头部和尾部执行添加或删除操作，提供了更高的灵活性。 双向队列支持在队列的两端执行常数级别的增删操作，即时间复杂度为O(1)O(1)O(1). 双向队列常见应用场景 滑动窗口算法：例如，在求解数组中连续子数组的最大和问题时，可以使用双向队列来存储当前窗口内的元素，通过不断地调整窗口的大小和更新队列中的元素，找到最大的子数组和； 设定上限的撤销与重做：考虑到系统资源限制，软件的撤销步数通常是有上限的，即软件需要在撤销队列的最底部（队首、栈底）删除最远的步数，但栈无法做到这一操作，这时便可以使用双向队列替代栈。 双向队列的两种实现方式 对应地，双向队列可以使用双向链表进行实现，在两端同时设计添加和删除节点功能。 数组实现则可参考队列的环形数组实现方案，在单向队列的基础上增加头节点（队尾）的删除和尾节点（队首）的添加功能。 STL deque C++ STL deque容器提供如下操作： STL 函数 描述 操作时间复杂度 empty() 判断双向队列是否为空 O(1)O(1)O(1) size() 返回双向队列中元素的个数 O(1)O(1)O(1) front() 返回双向队列的第一个元素的引用 O(1)O(1)O(1) back() 返回双向队列的最后一个元素的引用 O(1)O(1)O(1) push_front(element) 在双向队列的头部插入元素 O(1)O(1)O(1) push_back(element) 在双向队列的尾部插入元素 O(1)O(1)O(1) pop_front() 删除双向队列的第一个元素 O(1)O(1)O(1) pop_back() 删除双向队列的最后一个元素 O(1)O(1)O(1) ","link":"https://timestarry.github.io/post/ds-stack-queue/"},{"title":"链表","content":"链表的基础知识 链表节点需存储值和一个next指针，所以在相同数据量下，链表比数组占用更多空间； 在链表中插入/删除元素的时间复杂度为O(1)O(1)O(1)； 在链表中访问/查找元素的时间复杂度为O(n)O(n)O(n)； 链表与数组 对比项 数组 链表 存储方式 连续的内存空间 非连续的内存空间，通过节点的指针连接 随机访问 支持随机访问，可以通过下标在 O(1)O(1)O(1) 时间内访问任意元素 不支持随机访问，访问特定元素需要从链表头开始遍历，时间复杂度为 O(n)O(n)O(n) 插入/删除操作 在中间位置插入或删除元素时，需要移动大量元素，时间复杂度为 O(n)O(n)O(n) 只需要修改指针，时间复杂度为 O(1)O(1)O(1)（在已知节点位置的情况下） 内存分配 分配连续的大块内存，可能会出现内存不足导致分配失败的情况 按需分配内存，较为灵活 内存开销 除了存储数据本身，只需要少量额外的空间记录数组长度等信息 每个节点都需要额外的空间存储指针，内存开销相对较大 适用场景 适合频繁随机访问，元素数量相对固定的场景 适合频繁插入、删除操作，元素数量动态变化较大的场景 链表结构 设计链表 设计链表包含这些关键元素：链表节点（值和next指针）、初始化构造函数、访问、插入、删除、遍历方法。 设计链表-代码随想录 (programmercarl.com) 707. 设计链表 - 力扣（LeetCode） 测试通过代码： #include&lt;iostream&gt; class MyLinkedList { public: struct LinkedNode { int val; LinkedNode* next; LinkedNode() : val(0), next(nullptr) {}; LinkedNode(int _val) :val(_val), next(nullptr) {}; }; MyLinkedList() { this-&gt;_dummyHead = new LinkedNode(); this-&gt;_size = 0; } int get(int index) { if (index &lt; 0 || index &gt; _size - 1) { return -1; } LinkedNode* cur = _dummyHead-&gt;next; while (index--) { cur = cur-&gt;next; } return cur-&gt;val; } void addAtHead(int val) { LinkedNode* newNode = new LinkedNode(val); newNode-&gt;next = _dummyHead-&gt;next; _dummyHead-&gt;next = newNode; _size++; } void addAtTail(int val) { LinkedNode* newNode = new LinkedNode(val); LinkedNode* cur = _dummyHead; while (cur-&gt;next != nullptr) { cur = cur-&gt;next; } cur-&gt;next = newNode; _size++; } void addAtIndex(int index, int val) { if (index &lt; 0 || index &gt; _size) { return; } LinkedNode* newNode = new LinkedNode(val); LinkedNode* cur = _dummyHead; while (index--) { cur = cur-&gt;next; std::cout &lt;&lt;&quot;index = &quot; &lt;&lt; index &lt;&lt; &quot;cur-&gt;val = &quot; &lt;&lt; cur-&gt;val&lt;&lt;std::endl; } newNode-&gt;next = cur-&gt;next; cur-&gt;next = newNode; _size++; } void deleteAtIndex(int index) { if (index &lt; 0 || index &gt; _size - 1) { return; } LinkedNode* cur = _dummyHead; while (index--) { cur = cur-&gt;next; } cur-&gt;next = cur-&gt;next-&gt;next; _size--; } void printLinkedList() { LinkedNode* cur = _dummyHead-&gt;next; while (cur) { std::cout &lt;&lt; cur-&gt;val &lt;&lt; &quot; &quot;; cur = cur-&gt;next; } std::cout &lt;&lt; std::endl; std::cout &lt;&lt; &quot;size:&quot; &lt;&lt; _size &lt;&lt; std::endl; } private: LinkedNode* _dummyHead; int _size; }; 常见链表结构 除了单链表外，还有两种常见的链表类型： 环形链表：链表的尾节点指向它的头节点，即可得到一个环形链表；在环形链表中，任意节点都可以被视为头节点； 双向链表：不同于单链表，双向链表中还放有它前驱节点的pre指针，其遍历灵活性更强，但占用空间也更多。 常考题型 链表成环 力扣：142. 环形链表 II - 力扣（LeetCode） 难度：中等 考察重点 确认链表是否成环； 快指针追上慢指针的原理； 找到链表环的入口； 寻找入口过程中三个指针走过的路程涉及的数学关系。 合并链表 力扣：21. 合并两个有序链表 - 力扣（LeetCode） 难度：简单 考察重点 双指针； 虚拟头节点； 递归或迭代。 拓展（困难）：23. 合并 K 个升序链表 - 力扣（LeetCode） ","link":"https://timestarry.github.io/post/ds-linklist/"},{"title":"C++11智能指针","content":"C++98中的auto_ptr存在诸多问题，未被广泛使用。在C++11标准库中真正引入了智能指针，包括unique_ptr，shared_ptr和weak_ptr，智能指针的设计初衷就是为了帮助开发者管理内存。 unique_ptr std::unique_ptr&lt;T&gt;比std::shared_ptr&lt;T&gt;具有更小的内存，而且不需要维护引用计数，因此它的性能更好。当我们需要一个独占的指针时，应该优先使用unique_ptr。 特性 字面意思，unique_ptr最大的特性就是独占所有权，即同一时间只能有一个 unique_ptr 拥有某个对象的所有权。它能够自动管理内存并在不再使用时释放资源，从而避免内存泄漏。 独占所有权：独占所指对象的所有权，不能共享； 不能复制：禁止拷贝，确保了资源的唯一所有权； 自动销毁：当 unique_ptr 离开其作用域时（如函数结束或对象被销毁），它会自动释放所指向的资源，不需要显式调用 delete； 轻量高效：相比于 shared_ptr，unique_ptr 没有额外的引用计数开销。 特性实现 独占所有权 禁止拷贝： // 删除了拷贝构造函数，确保同一时间只有一个 MyUniquePtr 对象拥有资源的所有权，防止拷贝操作 MyUniquePtr(const MyUniquePtr&amp; other) = delete; // 删除了拷贝赋值操作符，确保不会通过赋值创建多个 MyUniquePtr 对象同时管理同一资源 MyUniquePtr&amp; operator=(const MyUniquePtr&amp; other) = delete; 移动语义： // 移动构造函数：转移所有权 MyUniquePtr(MyUniquePtr&amp;&amp; other) noexcept : ptr(other.ptr) { other.ptr = nullptr; // 将源指针置空，确保只有一个指针管理资源 } MyUniquePtr&amp; operator=(MyUniquePtr&amp;&amp; other) noexcept { if (this != &amp;other) { // 防止自我赋值 delete ptr; // 释放当前持有的资源 ptr = other.ptr; // 转移新资源的所有权 other.ptr = nullptr; // 将源指针置空 } return *this; } 自动销毁 析构释放： // 析构函数：释放管理的资源 ~MyUniquePtr() { delete ptr; // 自动删除所管理的对象 } 访问对象 // 重载 * 操作符，方便访问对象 T&amp; operator*() const { return *ptr; } // 重载 -&gt; 操作符，方便访问对象的成员 T* operator-&gt;() const { return ptr; } // 获取原始指针 T* get() const { return ptr; } // 放弃所有权，不删除对象，并返回指针 T* release() { T* temp = ptr; ptr = nullptr; return temp; } shared_ptr 通常用于一些资源创建昂贵比较耗时的场景， 比如涉及到文件读写、网络连接、数据库连接等。当需要共享资源的所有权时，例如，一个资源需要被多个对象共享，但是不知道哪个对象会最后释放它，这时候就可以使用std::shared_ptr&lt;T&gt;。 特性 不同于unique，shared_ptr可以共享所有权，并引入了引用计数特性。 共享所有权：多个 shared_ptr 对象可以共享管理同一个资源； 引用计数：维护一个引用计数，每当有新的 shared_ptr 复制或移动该资源时，引用计数会增加；当某个 shared_ptr 被销毁时，引用计数减少。只有当引用计数为零时，资源才会被释放； 线程安全的引用计数：shared_ptr 的引用计数操作是线程安全的，因此它可以安全地在多线程环境下使用； 联动weak_ptr：与 weak_ptr 协作，防止循环引用的问题。 特性实现 共享所有权 MySharedPtr 支持拷贝构造和赋值操作，通过增加引用计数实现共享所有权。 // 拷贝构造函数，增加引用计数 MySharedPtr(const MySharedPtr&amp; other) : ptr(other.ptr), ref_count(other.ref_count) { (*ref_count)++; // 引用计数增加 std::cout &lt;&lt; &quot;Copied shared_ptr, ref_count = &quot; &lt;&lt; *ref_count &lt;&lt; std::endl; } 引用计数 ref_count 用于跟踪有多少个 MySharedPtr 对象共享同一个资源。每当有新的 MySharedPtr 对象拷贝构造时，引用计数增加；当一个对象被销毁时，引用计数减少。 // 构造函数 explicit MySharedPtr(T* p = nullptr) : ptr(p), ref_count(new int(1)) { std::cout &lt;&lt; &quot;Created shared_ptr, ref_count = 1&quot; &lt;&lt; std::endl; } // 赋值运算符，处理引用计数 MySharedPtr&amp; operator=(const MySharedPtr&amp; other) { if (this != &amp;other) { // 先减少当前对象的引用计数 release(); // 复制新对象的指针和引用计数 ptr = other.ptr; ref_count = other.ref_count; (*ref_count)++; // 引用计数增加 std::cout &lt;&lt; &quot;Assigned shared_ptr, ref_count = &quot; &lt;&lt; *ref_count &lt;&lt; std::endl; } return *this; } 线程安全 shared_ptr 使用了原子操作来管理其引用计数。因此，当多个线程同时复制、销毁或重新赋值 shared_ptr 时，引用计数的增减操作是原子性的，不会发生竞态条件（race condition）。 weak_ptr 常用于数据结构中防止 shared_ptr 之间的循环依赖。例如在树结构、图结构或观察者模式中，经常使用 weak_ptr 来防止内存泄漏。当你不希望影响对象生命周期，但需要临时访问某个对象时，可以使用 weak_ptr。 特性 不影响引用计数：weak_ptr 不会增加 shared_ptr 的强引用计数。这意味着，即使有 weak_ptr 指向某个对象，当所有 shared_ptr 都销毁时，该对象仍然会被释放。 避免循环引用：在复杂的数据结构中，两个对象可能互相引用。如果双方都使用 shared_ptr，则会产生循环引用，导致内存泄漏。使用 weak_ptr 可以解决这个问题，因为 weak_ptr 不会阻止对象的销毁。 只能通过 lock() 获取对象：由于 weak_ptr 不直接拥有对象，它无法直接访问被引用的对象。需要调用 lock() 方法将其转换为 shared_ptr，这样可以确保在访问对象时对象仍然存在。 特性实现 不影响生命周期 weak_ptr 和 shared_ptr 共享同一个控制块，这个控制块包含了两个计数器： 强引用计数：跟踪有多少个 shared_ptr 实例引用同一个对象。 弱引用计数：跟踪有多少个 weak_ptr 引用该对象。 控制块不仅存储对象的引用计数，还保存着对象的指针（对象的地址）。当 shared_ptr 引用的对象被销毁时，控制块不会立即被释放，因为 weak_ptr 可能还在使用它。 weak_ptr 不会增加对象的强引用计数，因此它不会影响对象的生命周期。即使有多个 weak_ptr 引用该对象，当所有的 shared_ptr 被销毁时，强引用计数为 0，资源会被释放。 这通过引用计数的拆分实现，weak_ptr 只影响弱引用计数，不会干涉 shared_ptr 的强引用计数。 weak_ptr() : ptr_(nullptr), ref_count_(nullptr), weak_count_(nullptr) {} weak_ptr(const shared_ptr&lt;T&gt;&amp; sharedPtr) : ptr_(sharedPtr.ptr_), ref_count_(sharedPtr.ref_count_), weak_count_(sharedPtr.weak_count_) { if (weak_count_) (*weak_count_)++; } 避免循环引用 weak_ptr 最典型的用途是解决循环引用问题。在两个对象互相引用时，如果都使用 shared_ptr，对象将无法自动释放，因为它们的强引用计数永远不会降到 0。weak_ptr 通过不增加强引用计数来打破这个循环，使对象在强引用计数归零时能够被正确销毁。 访问对象 weak_ptr 没有直接访问对象的能力，需要通过 lock() 将自己转换为一个临时的 shared_ptr 来访问对象。 lock() 的实现原理是检查强引用计数是否大于 0。如果大于 0，表示对象还存在，于是 lock() 返回一个新的 shared_ptr，并增加强引用计数；如果强引用计数为 0，lock() 返回一个空的 shared_ptr。 shared_ptr&lt;T&gt; lock() const { // 检查强引用计数是否大于 0，如果大于 0，表示对象仍然存在 if (ref_count_ &amp;&amp; *ref_count_ &gt; 0) { return shared_ptr&lt;T&gt;(*this); // 创建并返回一个新的 shared_ptr } return shared_ptr&lt;T&gt;(nullptr); // 否则返回一个空的 shared_ptr } 参考阅读 C++ 智能指针最佳实践&amp;源码分析 - 知乎 (zhihu.com) cplusplus.com/reference/memory/ 万字长文全面详解现代C++智能指针：原理、应用和陷阱 - 七昂的技术之旅 - 博客园 (cnblogs.com) ","link":"https://timestarry.github.io/post/cpp11-smart-pointers/"}]}